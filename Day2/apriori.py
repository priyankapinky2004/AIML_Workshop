from mlxtend.preprocessing import TransactionEncoder
from mlxtend.frequent_patterns import apriori, association_rules
import pandas as pd

# ğŸ›’ Sample transactions
transactions = [
    ['milk', 'bread', 'eggs'],
    ['milk', 'diaper', 'beer', 'bread'],
    ['milk', 'diaper', 'beer', 'cola'],
    ['milk', 'bread', 'diaper'],
    ['milk', 'bread', 'eggs'],
    ['milk', 'diaper', 'cola'],
]

# ğŸ”„ Encode the transaction data into a DataFrame
te = TransactionEncoder()
te_ary = te.fit(transactions).transform(transactions)
df = pd.DataFrame(te_ary, columns=te.columns_)

print("ğŸ›’ Transaction DataFrame:")
print(df.head())

# ğŸ“Š Generate frequent itemsets
frequent_itemsets = apriori(df, min_support=0.4, use_colnames=True)
print("\nğŸ“Š Frequent Itemsets:")
print(frequent_itemsets)

# ğŸ“ˆ Generate association rules
rules = association_rules(frequent_itemsets, metric="support", min_threshold=0.4)
print("\nğŸ“ˆ Association Rules:")
print(rules)

# ğŸ”½ Sort rules by support
rules_sorted = rules.sort_values(by='support', ascending=False)

# âœ… Drop duplicate rules based on antecedents and consequents
rules_sorted = rules_sorted.drop_duplicates(subset=['antecedents', 'consequents']).reset_index(drop=True)

# ğŸ¯ Select top 20 rules
top20 = rules_sorted.head(20)

# ğŸ–¨ï¸ Display key columns of top rules
print("\nğŸ“Š Top 20 Association Rules:")
print(top20[['antecedents', 'consequents', 'support', 'confidence', 'lift']])
